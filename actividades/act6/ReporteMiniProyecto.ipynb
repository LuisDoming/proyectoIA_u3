{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte de Actividad 6 (Redes neuronales con TensorFlow y Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda actividad encargada para el mini proyecto trata de una aplicación hecha utilizando redes neuronales a travez de una librería de código abierto para aprendizaje automático (TensorFlow) junto con su api para construir y entrenar modelos (Keras), dicha aplicación se encarga de clasificar imágenes de ropa sacadas de un dataset gratuito despues de haber entrenado una red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del código "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se sabe, tanto TensorFlow y Keras son usados para este proyecto por lo que deben de ser importados, al igual que otras librerias que nos ayudaran a la proyección de los resultados, también necesitaremos de importar el dataset de las imágenes de ropa, los datos de Fashion MNIST cuentan con un total de 60000 imagenes de entrenamiento y 10000 imagenes de evaluación donde cada imágen se compone de un tamaño de 28x28 pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# se importa la biblioteca Tensorflow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Se importa numpy para manejo de datos y matplotlib para grafica\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Se imprime la versión de tensorflow\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "#Importar el conjunto de datos Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "#Cargar el conjunto de datos, \n",
    "#Las imagenes y etiquetas que se usarán para el entrenamiento estan en (train_images, train_labels)\n",
    "#Las imagenes y etiquetas que se usarán para la prueba estan en ((test_images, test_labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del dataset, cada imagen cuenta con su etiqueta que menciona el tipo de clase en la que entra cada una de las imágenes, habiendo un total de 10 clases diferentes (Blusa/camiseta, pantalón, suéter, vestido, abrigo, sandalias, camisa, tenis, bolsa y bota), es importante declarar las clases dentro del código en ese orden para que pueda coincidir con las etiquetas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Blusa/Camiseta', 'Pantalón', 'Suéter', 'Vestido', 'Abrigo',\n",
    "               'Sandalias', 'Camisa', 'Tenis', 'Bolsa', 'Bota']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los datos deben de ser preprocesados antes de utilizarlos como entrenamiento, mas que nada para saber con certeza de que tenemos bien configurada la red neuronal y no se capta alguna incoherencia dentro de la misma, un paso muy importante cuando se tratan de datasets masivos donde nos resulte muy costoso computacionalmente hablando su entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    #Grafica en la subgráfica i \n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # Grafica la imagen i\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    #Incluye la etitqueta de la imagen 1\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una manera facil de saber si los datos son coherentes son mostrando en pantalla las primeras 25 imágenes junto con sus etiquetas para comprobar que se encuentran ordenadas correctamente, una vez sabiendo que los datos son correctos, ahora si se puede empezar a entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagenes/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se construye el modelo de redes neuronales, primero se tienen que definir las capas que tendrá, la primera capa transforma el formato de las imágenes a un arreglo de bidimensional de 28x28, a un arreglo unidimensional de 784 pixeles, la siguiente capa de 128 neuronas y la otra de 10 neuronas se relacionan para (por medio de puntuación) saber qué imagen se relaciona con cada una de las 10 clases existentes dentro del dataset. \n",
    "\n",
    "Ya al final se compila el modelo, donde se establecen los ajustes para algunos parámetros que son  (**loss** — Indica que tan bueno es el modelo durante el entrenamiento. **Optimizer** — Para que modelo se actualice basado en los datos y vea como es la función loss. Y **Metrics** — Se usa para monitorear los pasos de entrenamiento y de prueba.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las capas\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo compilado ya se puede entrenar llamando al método **model.fit** para que el modelo se ajuste a los datos de entrenamiento. En lo que el modelo se entrena, se despliega la pérdida (valor de loss) y la métrica de exactitud (valor de accuracy). Este modelo llega a una exactitud de cerca de 0.88 (o 88%) en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con eso podemos evaluar la exactitud conseguida al ver el desempeño del modelo, y como ya se va a encontrar entrenado, ya podemos hacer predicciones con este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo en los datos de prueba, la pérdida (loss) se almacena en test_loss, la exactitud en test_acc\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#Predecir sobre las imagenes de prueba\n",
    "predictions = model.predict(test_images)\n",
    "predictions[0]\n",
    "\n",
    "#Encotrar la etiqueta con el valor más alto\n",
    "np.argmax(predictions[0])\n",
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados Finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el algoritmo ya configurado, compilado y entrenado ya podemos visualizar todas las predicciones que puede hacer, es solo cuestion de desplegar en pantalla lo que ocupemos ver utilizando **matplotlib**\n",
    "<img src=\"imagenes/3.png\"> <img src=\"imagenes/4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí por ejemplo podemos ver cómo el algoritmo infiere un 100% en que la imagen proporcionada es un pantalon, sin inferir que podría ser otra prenda, cosa que era de esperarse porque un pantalon puede distinguirse fácil de cualquier otra prenda por su estructura, sin embargo en la segunda pantalla vemos que predice que la imagen es un zapato a su vez que lo llegó a comparar con otro tipo de prenda , probablemente en tenis o botas, aunque quien predominó en este caso fue el zapato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagenes/5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente pantalla podemos ver las predicciones hechas en un volumen mayor de imágenes sacadas del dataset, se conforma por la imagen, su descripción, su porcentaje de exactitud, junto con una gráfica que muestra que tan acertada estaba de una u otra clasificación cada una de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagenes/6.png\"> \n",
    "\n",
    "Ya para terminar, aunque las gráficas mostradas anteriormente no nos muestran que significan cada una de las barras debido a que no cabría dentro de la información de la pantalla, aquí tenemos un vistazo más cercano a los posibles valores que puede tener una gráfica, donde vemos que para la primer imagen de todas (la bota mostrada en la primer pantalla) alcanzó a tener un cierto parecido con los tenis, pero no lo suficientemente notorio como para ser considerado uno.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
